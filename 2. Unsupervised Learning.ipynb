{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\"> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>Machine Learning with PyTorch for Developers</h1>\n",
    "<h1>Machine Learning Overview</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by print out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autopep8  1.5\n",
      "numpy     1.18.1\n",
      "json      2.0.9\n",
      "pandas    1.0.1\n",
      "watermark 2.0.2\n",
      "Mon May 11 2020 \n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 6.2.1\n",
      "\n",
      "compiler   : Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "system     : Darwin\n",
      "release    : 19.4.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : f06693032ded22cc83a4db4c4a7a590c1fa4bc94\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('./d4sci.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA(nn.Module):\n",
    "    def __init__(self, n_components):\n",
    "        super().__init__()\n",
    "        self.n_components = n_components\n",
    "        self.mean = None\n",
    "        self.components = None\n",
    "        self.explained_variance = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit the PCA model\n",
    "        X: input tensor of shape [n_samples, n_features]\n",
    "        \"\"\"\n",
    "        # Center the data\n",
    "        self.mean = torch.mean(X, dim=0)\n",
    "        X_centered = X - self.mean\n",
    "        \n",
    "        # Compute covariance matrix\n",
    "        N = X.size(0)\n",
    "        cov = torch.mm(X_centered.t(), X_centered) / (N - 1)\n",
    "        \n",
    "        # Compute eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = torch.linalg.eigh(cov)\n",
    "        \n",
    "        # Sort eigenvalues and eigenvectors in descending order\n",
    "        idx = torch.argsort(eigenvalues, descending=True)\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        # Store principal components and explained variance\n",
    "        self.components = eigenvectors[:, :self.n_components]\n",
    "        self.explained_variance = eigenvalues[:self.n_components]\n",
    "        \n",
    "        # Calculate explained variance ratio\n",
    "        self.explained_variance_ratio = eigenvalues[:self.n_components] / torch.sum(eigenvalues)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform data\n",
    "        X: input tensor of shape [n_samples, n_features]\n",
    "        \"\"\"\n",
    "        X_centered = X - self.mean\n",
    "        return torch.mm(X_centered, self.components)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Fit and transform in one step\n",
    "        \"\"\"\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "# Example usage (commented out):\n",
    "# X = torch.randn(100, 10)  # 100 samples, 10 features\n",
    "# pca = PCA(n_components=2)\n",
    "# X_transformed = pca.fit_transform(X)\n",
    "# print(f\"Explained variance ratio: {pca.explained_variance_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Implementation in PyTorch\n",
    "# We assume torch is already imported from previous cells.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class KMeans(nn.Module):\n",
    "    def __init__(self, n_clusters, max_iter=100):\n",
    "        super().__init__()\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        data: A tensor of shape [N, D] where N is the number of samples, and D is the number of features.\n",
    "        Returns:\n",
    "        - cluster_assignments: Tensor of shape [N], each element is the cluster index for each data point.\n",
    "        - centroids: Tensor of shape [n_clusters, D], the final cluster centers.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Initialize cluster centers by picking random points from data\n",
    "        indices = torch.randperm(data.size(0))[:self.n_clusters]\n",
    "        centroids = data[indices]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # 2. Compute distances between data points and centroids\n",
    "            #    We use broadcasting to find squared distances to each centroid.\n",
    "            distances = torch.cdist(data, centroids, p=2)\n",
    "\n",
    "            # 3. Assign each data point to the closest centroid\n",
    "            cluster_assignments = distances.argmin(dim=1)\n",
    "\n",
    "            # 4. Update the centroids based on current cluster assignments\n",
    "            new_centroids = []\n",
    "            for k in range(self.n_clusters):\n",
    "                cluster_points = data[cluster_assignments == k]\n",
    "                if len(cluster_points) > 0:\n",
    "                    new_centroids.append(cluster_points.mean(dim=0))\n",
    "                else:\n",
    "                    # If no points are assigned to a cluster, keep the old centroid\n",
    "                    new_centroids.append(centroids[k])\n",
    "            new_centroids = torch.stack(new_centroids)\n",
    "\n",
    "            # 5. Check if centroids have changed significantly\n",
    "            if torch.allclose(centroids, new_centroids, atol=1e-4):\n",
    "                break\n",
    "            centroids = new_centroids\n",
    "\n",
    "        return cluster_assignments, centroids\n",
    "\n",
    "# Usage Example (uncomment to run):\n",
    "# data_tensor = torch.randn(100, 2)\n",
    "# kmeans = KMeans(n_clusters=3, max_iter=10)\n",
    "# assignments, final_centroids = kmeans(data_tensor)\n",
    "# print(\"Cluster Assignments:\", assignments)\n",
    "# print(\"Final Centroids:\", final_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Introduction to PyTorch basics\n",
    "print(\"PyTorch Introduction:\")a\n",
    "\n",
    "# 1. Creating a simple Neural Network Layer\n",
    "linear = torch.nn.Linear(in_features=2, out_features=1)\n",
    "print(f\"\\nNeural Network Layer:\\n{linear}\")\n",
    "\n",
    "# 2. Define a simple optimization problem\n",
    "# Create random input data\n",
    "X = torch.randn(10, 2)  # 10 samples, 2 features\n",
    "y = torch.randn(10, 1)  # 10 targets\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# 3. Simple training loop example\n",
    "print(\"\\nTraining Loop Example:\")\n",
    "for epoch in range(5):\n",
    "    # Forward pass\n",
    "    y_pred = linear(X)\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"\\nOptimization components:\")\n",
    "print(f\"Optimizer: {type(optimizer).__name__}\")\n",
    "print(f\"Loss Function: {type(criterion).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "     <img src=\"data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
