{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\"> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>Machine Learning with PyTorch for Developers</h1>\n",
    "<h1>Machine Learning Overview</h1>\n",
    "        <p>Bruno Gonçalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by print out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.7\n",
      "IPython version      : 9.0.0\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.3.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 46fd989832f97305d47c167037aa491a1802660f\n",
      "\n",
      "torch     : 2.6.0\n",
      "matplotlib: 3.10.1\n",
      "numpy     : 2.2.3\n",
      "watermark : 2.5.0\n",
      "pandas    : 2.2.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('./d4sci.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Training loop example\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m     61\u001b[39m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         predictions = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m         loss = loss_fn(predictions, targets)\n\u001b[32m     65\u001b[39m         \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/pytorch-z-pj7ewX-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/pytorch-z-pj7ewX-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mSimpleFeedForwardNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     46\u001b[39m         \u001b[38;5;66;03m# Use torch.nn.functional for activation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m         x = \u001b[43mF\u001b[49m.relu(\u001b[38;5;28mself\u001b[39m.fc1(x))\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc2(x)\n",
      "\u001b[31mNameError\u001b[39m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Below is an illustrative overview of PyTorch fundamentals, focusing on torch.nn and\n",
    "torch.nn.functional for defining and implementing optimization problems.\n",
    "\n",
    "1. Tensor Basics\n",
    "----------------\n",
    "PyTorch tensors are array-like structures that can run on CPU or GPU. They support\n",
    "autograd, meaning gradients are automatically calculated for operations on tensors\n",
    "marked with requires_grad=True.\n",
    "\n",
    "2. torch.nn\n",
    "-----------\n",
    "• Provides building blocks for neural networks (e.g., Linear, Conv2d).\n",
    "• Encapsulates parameters (weights/biases) that are automatically tracked.\n",
    "\n",
    "3. torch.nn.functional\n",
    "----------------------\n",
    "• Contains functional forms of common layers and activation functions (e.g., F.relu, F.sigmoid).\n",
    "• Often used inside the forward() method without creating explicit layer objects.\n",
    "\n",
    "4. Defining a Model\n",
    "-------------------\n",
    "• Inherit from nn.Module.\n",
    "• Define the layers in __init__.\n",
    "• Specify forward pass in forward().\n",
    "\n",
    "5. Optimization\n",
    "---------------\n",
    "• Use built-in optimizers (e.g., torch.optim.SGD, torch.optim.Adam). \n",
    "• Typically define a loss function (e.g., nn.MSELoss, nn.CrossEntropyLoss) and call\n",
    "    loss.backward() to compute gradients, then optimizer.step() to update parameters.\n",
    "\n",
    "--------------------------------------------------------\n",
    "Example: Simple feed-forward network with a training loop\n",
    "--------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# Simple feed-forward neural network with one hidden layer\n",
    "class SimpleFeedForwardNN(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size):\n",
    "                super(SimpleFeedForwardNN, self).__init__()\n",
    "                self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "                self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "                # Use torch.nn.functional for activation\n",
    "                x = F.relu(self.fc1(x))\n",
    "                return self.fc2(x)\n",
    "\n",
    "# Instantiate the model, define loss and optimizer\n",
    "model = SimpleFeedForwardNN(input_size=3, hidden_size=5, output_size=2)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create sample data (10 samples, each with 3 features)\n",
    "data = torch.randn(10, 3)\n",
    "targets = torch.randn(10, 2)\n",
    "\n",
    "# Training loop example\n",
    "for epoch in range(5):\n",
    "        # Forward pass\n",
    "        predictions = model(data)\n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Introduction to PyTorch tensors and basic operations\n",
    "print(\"PyTorch Fundamentals:\\n\")\n",
    "\n",
    "# 1. Tensor Creation Methods\n",
    "print(\"Different ways to create tensors:\")\n",
    "# From Python list\n",
    "list_tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "# From numpy array\n",
    "numpy_tensor = torch.from_numpy(np.array([[1, 2], [3, 4]]))\n",
    "# Special tensors\n",
    "range_tensor = torch.arange(0, 10, step=2)\n",
    "linspace_tensor = torch.linspace(0, 10, steps=5)\n",
    "\n",
    "print(f\"From list:\\n{list_tensor}\")\n",
    "print(f\"\\nRange tensor:\\n{range_tensor}\")\n",
    "print(f\"\\nLinspace tensor:\\n{linspace_tensor}\")\n",
    "\n",
    "# 2. Tensor Operations and Manipulations\n",
    "print(\"\\nTensor Operations:\")\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(f\"Matrix multiplication:\\n{torch.mm(a, b)}\")\n",
    "print(f\"\\nElement-wise multiplication:\\n{a * b}\")\n",
    "print(f\"\\nTranspose:\\n{a.t()}\")\n",
    "\n",
    "# 3. Autograd Example\n",
    "print(\"\\nAutograd Demonstration:\")\n",
    "x = torch.tensor([[1., 2.]], requires_grad=True)\n",
    "y = torch.tensor([[3., 4.]], requires_grad=True)\n",
    "z = torch.sum(x * y)\n",
    "\n",
    "print(f\"Input x: {x}\")\n",
    "print(f\"Input y: {y}\")\n",
    "print(f\"z = sum(x * y): {z}\")\n",
    "\n",
    "z.backward()\n",
    "print(f\"\\nGradient of z with respect to x: {x.grad}\")\n",
    "print(f\"Gradient of z with respect to y: {y.grad}\")\n",
    "\n",
    "# 4. Neural Network Components\n",
    "print(\"\\nNeural Network Building Blocks:\")\n",
    "# Common activation functions\n",
    "input_tensor = torch.randn(3)\n",
    "print(f\"Input: {input_tensor}\")\n",
    "print(f\"ReLU: {F.relu(input_tensor)}\")\n",
    "print(f\"Sigmoid: {torch.sigmoid(input_tensor)}\")\n",
    "print(f\"Tanh: {torch.tanh(input_tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tensor operations\n",
    "print(\"Creating tensors:\")\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "y = torch.tensor([5, 6, 7, 8])\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "\n",
    "print(\"\\nBasic operations:\")\n",
    "print(f\"Addition: {x + y}\")\n",
    "print(f\"Multiplication: {x * y}\")\n",
    "\n",
    "# Creating different types of tensors\n",
    "print(\"\\nDifferent tensor types:\")\n",
    "zeros = torch.zeros(3, 3)\n",
    "ones = torch.ones(2, 2)\n",
    "random_tensor = torch.rand(2, 3)\n",
    "\n",
    "print(f\"Zeros:\\n{zeros}\")\n",
    "print(f\"\\nOnes:\\n{ones}\")\n",
    "print(f\"\\nRandom:\\n{random_tensor}\")\n",
    "\n",
    "# Tensor properties\n",
    "print(\"\\nTensor properties:\")\n",
    "print(f\"Shape of random tensor: {random_tensor.shape}\")\n",
    "print(f\"Data type of x: {x.dtype}\")\n",
    "print(f\"Device (CPU/GPU): {x.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Introduction to PyTorch basics\n",
    "print(\"PyTorch Introduction:\")\n",
    "\n",
    "# 1. Creating a simple Neural Network Layer\n",
    "linear = torch.nn.Linear(in_features=2, out_features=1)\n",
    "print(f\"\\nNeural Network Layer:\\n{linear}\")\n",
    "\n",
    "# 2. Define a simple optimization problem\n",
    "# Create random input data\n",
    "X = torch.randn(10, 2)  # 10 samples, 2 features\n",
    "y = torch.randn(10, 1)  # 10 targets\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# 3. Simple training loop example\n",
    "print(\"\\nTraining Loop Example:\")\n",
    "for epoch in range(5):\n",
    "    # Forward pass\n",
    "    y_pred = linear(X)\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"\\nOptimization components:\")\n",
    "print(f\"Optimizer: {type(optimizer).__name__}\")\n",
    "print(f\"Loss Function: {type(criterion).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "     <img src=\"data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
